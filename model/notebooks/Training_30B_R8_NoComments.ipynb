{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tam1444AH/UH-Insure-NSA/blob/main/notebooks/codeLLMFT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vhsfjOTsdjHg",
        "outputId": "5bae6ca7-1325-42c3-dcc5-bfa6964ff0dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nbstripout in /usr/local/lib/python3.12/dist-packages (0.8.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.12/dist-packages (from nbstripout) (5.10.4)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat->nbstripout) (2.21.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat->nbstripout) (4.25.1)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.12/dist-packages (from nbformat->nbstripout) (5.9.1)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.12/dist-packages (from nbformat->nbstripout) (5.7.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->nbstripout) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->nbstripout) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->nbstripout) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->nbstripout) (0.28.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->nbstripout) (4.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from referencing>=0.28.4->jsonschema>=2.6->nbformat->nbstripout) (4.15.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (0.36.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.34.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.34.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.34.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.34.0) (2025.10.5)\n",
            "ipython 7.34.0 requires jedi, which is not installed.\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (0.1.9)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.48.1)\n",
            "Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.8.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.17.1)\n",
            "Requirement already satisfied: flash-attn in /usr/local/lib/python3.12/dist-packages (2.8.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from peft) (2.8.0+cu126)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from peft) (1.11.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from flash-attn) (0.8.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.3)\n",
            "Repo 'Colab-Training' exists, pulling latest changes...\n",
            "HEAD is now at 9186329 No comment data set\n",
            "Already up to date.\n",
            "* \u001b[32mmain\u001b[m\n",
            "  \u001b[31mremotes/origin/HEAD\u001b[m -> origin/main\n",
            "  \u001b[31mremotes/origin/main\u001b[m\n"
          ]
        }
      ],
      "source": [
        "%pip install nbstripout\n",
        "%pip install -U \"huggingface-hub>=0.34.0,<1.0\"\n",
        "%pip check\n",
        "%pip install hf_transfer\n",
        "%pip install -U bitsandbytes --upgrade\n",
        "%pip install transformers datasets\n",
        "%pip install transformers datasets peft flash-attn\n",
        "!export HF_HUB_ENABLE_HF_TRANSFER=1\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import json, random\n",
        "from datasets import load_dataset, Dataset, concatenate_datasets\n",
        "from transformers import AutoTokenizer\n",
        "import os\n",
        "import wandb\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "from google.colab import userdata\n",
        "from huggingface_hub import login, whoami\n",
        "os.environ[\"WANDB_DISABLED\"] = \"false\"  # or \"true\" to mute\n",
        "os.environ[\"WANDB_PROJECT\"]   = \"qwen3coder-finetune-fp16\"\n",
        "\n",
        "os.environ[\"WANDB_LOG_MODEL\"] = \"false\"\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"  # mitigate fragmentation\n",
        "REPO_URL=\"https://github.com/UH-Insure/Colab-Training.git\"\n",
        "REPO=\"Colab-Training\"\n",
        "\n",
        "os.chdir(\"/content\")\n",
        "\n",
        "# If repo exists, update it; otherwise, clone fresh\n",
        "if os.path.exists(REPO):\n",
        "    print(f\"Repo '{REPO}' exists, pulling latest changes...\")\n",
        "    os.chdir(REPO)\n",
        "    !git reset --hard HEAD   # optional: discard local changes\n",
        "    !git pull\n",
        "else:\n",
        "    print(f\"Cloning repo '{REPO}'...\")\n",
        "    !git clone \"$REPO_URL\" \"$REPO\"\n",
        "    os.chdir(REPO)\n",
        "\n",
        "!nbstripout --install\n",
        "!git branch -a\n",
        "\n",
        "\n",
        "# Install dependencies if present\n",
        "if os.path.exists(\"requirements.txt\"):\n",
        "    %pip install -r requirements.txt\n",
        "if os.path.exists(\"pyproject.toml\"):\n",
        "    %pip install -e .\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d83XoDttGhvR",
        "outputId": "b0a37491-d2c0-47f3-b4ee-b4d9564e1c29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello World!\n"
          ]
        }
      ],
      "source": [
        "from model.test import test\n",
        "test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYAEaTXfi5IL",
        "outputId": "cbf77d50-f7b8-4cb6-9756-f8b41e0fa779"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjoshuareedenterprises\u001b[0m (\u001b[33mjoshuareedenterprises-university-of-houston\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
            "WARNING:huggingface_hub._login:Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logged in as: j05hr3d\n"
          ]
        }
      ],
      "source": [
        "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"\n",
        "HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "WANDB_TOKEN = userdata.get('WANDB_KEY')\n",
        "os.environ[\"WANDB_API_KEY\"] = WANDB_TOKEN\n",
        "os.environ[\"HF_TOKEN\"] = HF_TOKEN\n",
        "wandb.login(key=WANDB_TOKEN, relogin=True)\n",
        "login(token=HF_TOKEN, add_to_git_credential=True)  # also sets Git creds for LFS\n",
        "\n",
        "print(\"Logged in as:\", whoami(token=HF_TOKEN)[\"name\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "_exHfg8sVH3J",
        "outputId": "fa0a06ff-c874-4d8e-e348-b37f690361f9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.22.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/Colab-Training/wandb/run-20251028_195539-7sogfmpg</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/joshuareedenterprises-university-of-houston/qwen3coder-finetune-fp16/runs/7sogfmpg' target=\"_blank\">deep-plant-18</a></strong> to <a href='https://wandb.ai/joshuareedenterprises-university-of-houston/qwen3coder-finetune-fp16' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/joshuareedenterprises-university-of-houston/qwen3coder-finetune-fp16' target=\"_blank\">https://wandb.ai/joshuareedenterprises-university-of-houston/qwen3coder-finetune-fp16</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/joshuareedenterprises-university-of-houston/qwen3coder-finetune-fp16/runs/7sogfmpg' target=\"_blank\">https://wandb.ai/joshuareedenterprises-university-of-houston/qwen3coder-finetune-fp16/runs/7sogfmpg</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">deep-plant-18</strong> at: <a href='https://wandb.ai/joshuareedenterprises-university-of-houston/qwen3coder-finetune-fp16/runs/7sogfmpg' target=\"_blank\">https://wandb.ai/joshuareedenterprises-university-of-houston/qwen3coder-finetune-fp16/runs/7sogfmpg</a><br> View project at: <a href='https://wandb.ai/joshuareedenterprises-university-of-houston/qwen3coder-finetune-fp16' target=\"_blank\">https://wandb.ai/joshuareedenterprises-university-of-houston/qwen3coder-finetune-fp16</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20251028_195539-7sogfmpg/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.22.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/Colab-Training/wandb/run-20251028_195540-g4kceevr</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/joshuareedenterprises-university-of-houston/qwen3coder-finetune-fp16/runs/g4kceevr' target=\"_blank\">LoRA-Q-30B-R8-NoComments-20251028-195540</a></strong> to <a href='https://wandb.ai/joshuareedenterprises-university-of-houston/qwen3coder-finetune-fp16' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/joshuareedenterprises-university-of-houston/qwen3coder-finetune-fp16' target=\"_blank\">https://wandb.ai/joshuareedenterprises-university-of-houston/qwen3coder-finetune-fp16</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/joshuareedenterprises-university-of-houston/qwen3coder-finetune-fp16/runs/g4kceevr' target=\"_blank\">https://wandb.ai/joshuareedenterprises-university-of-houston/qwen3coder-finetune-fp16/runs/g4kceevr</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<wandb.sdk.wandb_metric.Metric at 0x7ac0ced129c0>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MODEL = \"Qwen/Qwen3-Coder-30B-A3B-Instruct\"\n",
        "DATASET = \"/content/Colab-Training/data/all_nocomments.jsonl\"\n",
        "DATA_COLUMN = \"content\"\n",
        "\n",
        "SEQ_LENGTH = 4096\n",
        "\n",
        "# Training arguments\n",
        "MAX_STEPS = 200\n",
        "NUM_EPOCHS = 50\n",
        "BATCH_SIZE = 12\n",
        "GR_ACC_STEPS = 2\n",
        "LR = 2e-5                     # learning_rate\n",
        "WARMUP_RATIO = 0.03\n",
        "WEIGHT_DECAY = 0.01\n",
        "LR_SCHEDULER_TYPE = \"cosine\"  # lr_scheduler_type\n",
        "WEIGHT_DECAY = 0.05  # weight_decay\n",
        "NUM_WARMUP_STEPS = 100  # num_warmup_steps\n",
        "EVAL_FREQ = 25\n",
        "SAVE_FREQ = 50\n",
        "LOG_FREQ = 10\n",
        "CUSTOM_WEIGHTS_NAME = \"LoRA-Q-30B-R8-NoComments\"\n",
        "OUTPUT_DIR = f\"j05hr3d/{CUSTOM_WEIGHTS_NAME}\"  # output_dir\n",
        "BF16 = True  # bf16\n",
        "FP16 = False  # no_fp16\n",
        "\n",
        "# FIM trasformations arguments\n",
        "FIM_RATE = 0.25  # fim_rate\n",
        "FIM_SPM_RATE = 0.5  # fim_spm_rate\n",
        "\n",
        "\n",
        "# LORA\n",
        "LORA_R = 8  # lora_r\n",
        "LORA_ALPHA = LORA_R * 2  # lora_alpha\n",
        "LORA_DROPOUT = 0.05  # lora_dropout\n",
        "LORA_TARGET_MODULES = [\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\"gate_proj\",\"up_proj\",\"down_proj\"]\n",
        "#LORA_TARGET_MODULES = [\"q_proj\",\"k_proj\",\"v_proj\"]  # lora_target_modules\n",
        "\n",
        "# bitsandbytes config\n",
        "USE_NESTED_QUANT = True  # use_nested_quant\n",
        "BNB_4BIT_COMPUTE_DTYPE = \"bfloat16\"  # bnb_4bit_compute_dtype\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "run = wandb.init()\n",
        "wandb.init(\n",
        "    project=\"qwen3coder-finetune-fp16\",\n",
        "    name=f\"{CUSTOM_WEIGHTS_NAME}-{datetime.now().strftime('%Y%m%d-%H%M%S')}\",\n",
        "    settings=wandb.Settings(\n",
        "      ignore_globs=[\"*.bin\",\"*.pt\",\"*.safetensors\",\"*.ckpt\",\"checkpoint*\"]\n",
        "))\n",
        "wandb.define_metric(\"train/global_step\")\n",
        "wandb.define_metric(\"train/*\", step_metric=\"train/global_step\")\n",
        "wandb.define_metric(\"eval/*\",  step_metric=\"train/global_step\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lRTsgnlVcMN"
      },
      "outputs": [],
      "source": [
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    logging,\n",
        "    set_seed,\n",
        "    BitsAndBytesConfig,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    TrainerCallback\n",
        ")\n",
        "\n",
        "set_seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlcO8zw22Ycd",
        "outputId": "042ad6c3-7510-4a15-ab2b-8eae6d826607"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['filename', 'filetype', 'content', 'variant', 'set'])\n",
            "dict_keys(['filename', 'filetype', 'content', 'variant', 'set'])\n",
            "671 76\n",
            "The character to token ratio of the dataset is: 2.04\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "from model.dataset.util import chars_token_ratio, split_by_filetype\n",
        "\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.set_float32_matmul_precision(\"high\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    MODEL,\n",
        "    padding_side=\"right\",\n",
        "    add_eos_token=True,\n",
        "    add_bos_token=True,\n",
        "    trust_remote_code=True,\n",
        "    use_fast=False,\n",
        ")\n",
        "\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "train_ds, eval_ds = split_by_filetype(\n",
        "    dataset_path=DATASET,\n",
        "    seed=SEED,\n",
        "    test_size=0.1,\n",
        "    filetypes=[\"cry\", \"saw\", \"txt\"]\n",
        ")\n",
        "print(train_ds[0].keys())\n",
        "assert DATA_COLUMN in train_ds.column_names, f\"Missing '{DATA_COLUMN}' in JSONL!\"\n",
        "print(eval_ds[0].keys())\n",
        "assert DATA_COLUMN in eval_ds.column_names, f\"Missing '{DATA_COLUMN}' in JSONL!\"\n",
        "print(len(train_ds), len(eval_ds))\n",
        "chars_per_token = chars_token_ratio(train_ds, tokenizer, DATA_COLUMN)\n",
        "print(f\"The character to token ratio of the dataset is: {chars_per_token:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WIZWSfIJBaS"
      },
      "outputs": [],
      "source": [
        "from model.dataset.util import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tC8QbrmIJBcm",
        "outputId": "58df76fb-a2a7-4375-80ee-c23d78d4c362"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Empirical dataset length = 223 sequences (~798384 tokens)\n",
            "[INFO] Empirical dataset length = 23 sequences (~79525 tokens)\n"
          ]
        }
      ],
      "source": [
        "from model.dataset.constantLengthDataset import ConstantLengthDataset\n",
        "import torch\n",
        "\n",
        "\n",
        "train_dataset = ConstantLengthDataset(\n",
        "        tokenizer=tokenizer,\n",
        "        dataset=train_ds,\n",
        "        infinite=False,\n",
        "        seq_length=SEQ_LENGTH,\n",
        "        chars_per_token=chars_per_token,\n",
        "        content_field=DATA_COLUMN,\n",
        "        fim_rate=FIM_RATE,\n",
        "        fim_spm_rate=FIM_SPM_RATE,\n",
        "        overlap_ratio=0.125,\n",
        "        seed=SEED,\n",
        "        already_tokenized=False,\n",
        ")\n",
        "eval_dataset = ConstantLengthDataset(\n",
        "        tokenizer=tokenizer,\n",
        "        dataset=eval_ds,\n",
        "        infinite=False,\n",
        "        seq_length=SEQ_LENGTH,\n",
        "        chars_per_token=chars_per_token,\n",
        "        content_field=DATA_COLUMN,\n",
        "        fim_rate=FIM_RATE,\n",
        "        fim_spm_rate=FIM_SPM_RATE,\n",
        "        overlap_ratio=0.125,\n",
        "        seed=SEED,\n",
        "        already_tokenized=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KltZZq0QbJFP"
      },
      "outputs": [],
      "source": [
        "import os, gc, torch\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "gc.collect(); torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120,
          "referenced_widgets": [
            "234c31a6de2c48fca38bc757d0b127df",
            "e006307864cb432eb8efdbd80e20a3cb",
            "18852e53fe7240cfadeb6e97c658e4b7",
            "4b07082637844f408e518f3856519fb9",
            "737369715f2d41c5bbdf54d2f4538819",
            "1dc855d3f9284307a66b15ef704e677a",
            "c183125c03f7472f8ce34aa98c6d6dd4",
            "b4a366d7e22c449cada4ccd9641302d9",
            "65a23814a7ee4ab9ac068f3c51f38d3a",
            "087ff63679e44f178cb9b49527d34216",
            "0538516fdd7044d68d689fa285057509"
          ]
        },
        "collapsed": true,
        "id": "6r7iIuyAJBg0",
        "outputId": "76552ebf-0e38-4948-9a16-1f0d8b6b37ab"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'<|fim_prefix|>': 151659, '<|fim_middle|>': 151660, '<|fim_suffix|>': 151661, '<|fim_pad|>': 151662}\n",
            "additional_special_tokens: ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "234c31a6de2c48fca38bc757d0b127df",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/16 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "from peft.tuners.lora import LoraLayer\n",
        "\n",
        "names = [\"<|fim_prefix|>\", \"<|fim_middle|>\", \"<|fim_suffix|>\", \"<|fim_pad|>\"]\n",
        "ids = [tokenizer.convert_tokens_to_ids(t) for t in names]\n",
        "print(dict(zip(names, ids)))\n",
        "print(\"additional_special_tokens:\", tokenizer.special_tokens_map.get(\"additional_special_tokens\"))\n",
        "\n",
        "\n",
        "# 4-bit quantization\n",
        "compute_dtype = getattr(torch, BNB_4BIT_COMPUTE_DTYPE)\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=compute_dtype,\n",
        "    bnb_4bit_use_double_quant=USE_NESTED_QUANT,\n",
        ")\n",
        "\n",
        "base = AutoModelForCausalLM.from_pretrained(\n",
        "        MODEL,\n",
        "        load_in_8bit=False,\n",
        "        quantization_config=bnb_config,\n",
        "        torch_dtype=torch.float16,\n",
        "        device_map=\"auto\",\n",
        "        use_cache=False,\n",
        "        trust_remote_code=True,\n",
        "        attn_implementation=\"flash_attention_2\",\n",
        ")\n",
        "\n",
        "base = prepare_model_for_kbit_training(base)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5monDpDR8_n",
        "outputId": "1a83e84e-93a7-4dec-fab2-dd0774fa940d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ATTN: Qwen3MoeAttention(\n",
            "  (q_proj): Linear4bit(in_features=2048, out_features=4096, bias=False)\n",
            "  (k_proj): Linear4bit(in_features=2048, out_features=512, bias=False)\n",
            "  (v_proj): Linear4bit(in_features=2048, out_features=512, bias=False)\n",
            "  (o_proj): Linear4bit(in_features=4096, out_features=2048, bias=False)\n",
            "  (q_norm): Qwen3MoeRMSNorm((128,), eps=1e-06)\n",
            "  (k_norm): Qwen3MoeRMSNorm((128,), eps=1e-06)\n",
            ")\n",
            "MLP: Qwen3MoeSparseMoeBlock(\n",
            "  (gate): Linear4bit(in_features=2048, out_features=128, bias=False)\n",
            "  (experts): ModuleList(\n",
            "    (0-127): 128 x Qwen3MoeMLP(\n",
            "      (gate_proj): Linear4bit(in_features=2048, out_features=768, bias=False)\n",
            "      (up_proj): Linear4bit(in_features=2048, out_features=768, bias=False)\n",
            "      (down_proj): Linear4bit(in_features=768, out_features=2048, bias=False)\n",
            "      (act_fn): SiLUActivation()\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "blk = base.model.layers[0]           # Llama/Qwen-style\n",
        "print(\"ATTN:\", blk.self_attn)         # has q_proj, k_proj, v_proj, o_proj\n",
        "print(\"MLP:\", blk.mlp)\n",
        "target_modules = LORA_TARGET_MODULES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RFqsImVJBjW",
        "outputId": "104e34df-47c5-431c-c6ad-85dd15ddade3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 421,920,768 || all params: 30,954,043,392 || trainable%: 1.3631\n"
          ]
        }
      ],
      "source": [
        "# Set up lora\n",
        "from peft import PeftModel\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha=LORA_ALPHA,\n",
        "    lora_dropout=LORA_DROPOUT,\n",
        "    r=LORA_R,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules=target_modules,\n",
        ")\n",
        "\n",
        "#model = PeftModel.from_pretrained(base, OUTPUT_DIR, is_trainable=True) # Get existing adapters\n",
        "model = get_peft_model(base, peft_config) # Create new LoRA adapters\n",
        "\n",
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bApn9UHJz7F"
      },
      "outputs": [],
      "source": [
        "collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "If0nsW1tJNQJ"
      },
      "outputs": [],
      "source": [
        "train_ds.start_iteration = 0\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=2,\n",
        "    gradient_accumulation_steps=2,\n",
        "    gradient_checkpointing=True,\n",
        "    learning_rate=LR,\n",
        "    lr_scheduler_type=LR_SCHEDULER_TYPE,\n",
        "    #warmup_steps=4,\n",
        "    warmup_ratio=WARMUP_RATIO,\n",
        "    weight_decay=0.0,\n",
        "    fp16=False,\n",
        "    bf16=True,\n",
        "    optim=\"adamw_torch\",\n",
        "    logging_steps=10,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=30,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=30,\n",
        "    hub_strategy=\"every_save\",\n",
        "    hub_model_id=OUTPUT_DIR,\n",
        "    report_to=[\"wandb\"],\n",
        "    push_to_hub=True,\n",
        "    dataloader_drop_last=False,\n",
        "    dataloader_num_workers=2,\n",
        "    include_tokens_per_second=True,\n",
        "    max_grad_norm=1.0,\n",
        "    save_total_limit=1,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    greater_is_better=False,\n",
        "    dataloader_pin_memory=True,\n",
        "    save_safetensors=True,\n",
        "    seed=SEED,\n",
        ")\n",
        "model.gradient_checkpointing_enable(gradient_checkpointing_kwargs={\"use_reentrant\": True})\n",
        "model.config.use_cache = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "hrZA8wr0JNSd",
        "outputId": "7c5cb51d-620a-416a-8748-a1d8658b6f21"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-335593966.py:6: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 151643}.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Casting fp32 inputs back to torch.bfloat16 for flash-attn compatibility.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='57' max='280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 57/280 1:48:47 < 7:21:07, 0.01 it/s, Epoch 2/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.081100</td>\n",
              "      <td>1.056067</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:751: UserWarning: Length of IterableDataset <model.dataset.constantLengthDataset.ConstantLengthDataset object at 0x7abff2f50860> was reported to be 23(when accessing len(dataloader)), but 24 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "from model.dataset.util import PerplexityCallback, EpochToDatasetCallback\n",
        "from time import time\n",
        "from transformers import EarlyStoppingCallback\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,         # required for early stopping\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=collator,\n",
        "    callbacks=[\n",
        "        PerplexityCallback(),\n",
        "        EpochToDatasetCallback(train_dataset),\n",
        "        EarlyStoppingCallback(\n",
        "            early_stopping_patience=2,\n",
        "            early_stopping_threshold=0.0\n",
        "        ),\n",
        "    ],\n",
        ")\n",
        "\n",
        "train_start_time = time()\n",
        "print(\"Training...\")\n",
        "try:\n",
        "  trainer.train(resume_from_checkpoint=False)\n",
        "  train_end_time = time()\n",
        "  print(f\"Training completed in {train_end_time - train_start_time:.2f} seconds.\")\n",
        "  eval_results = trainer.evaluate()\n",
        "except e as Exception:\n",
        "  print(f\"Training failed: {e}\")\n",
        "finally:\n",
        "  trainer.save_state()\n",
        "  trainer.save_model(f\"{trainer.args.output_dir}/last-safe\")\n",
        "wandb.finish()\n",
        "eval_loss = eval_results[\"eval_loss\"]\n",
        "perplexity = math.exp(eval_loss)\n",
        "print(f\"Eval loss = {eval_loss:.2f}, Perplexity = {perplexity:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-jKxX1UJdu5"
      },
      "outputs": [],
      "source": [
        "trainer.push_to_hub()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUWOrfbvicgn"
      },
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0538516fdd7044d68d689fa285057509": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "087ff63679e44f178cb9b49527d34216": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18852e53fe7240cfadeb6e97c658e4b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4a366d7e22c449cada4ccd9641302d9",
            "max": 16,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_65a23814a7ee4ab9ac068f3c51f38d3a",
            "value": 16
          }
        },
        "1dc855d3f9284307a66b15ef704e677a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "234c31a6de2c48fca38bc757d0b127df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e006307864cb432eb8efdbd80e20a3cb",
              "IPY_MODEL_18852e53fe7240cfadeb6e97c658e4b7",
              "IPY_MODEL_4b07082637844f408e518f3856519fb9"
            ],
            "layout": "IPY_MODEL_737369715f2d41c5bbdf54d2f4538819"
          }
        },
        "4b07082637844f408e518f3856519fb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_087ff63679e44f178cb9b49527d34216",
            "placeholder": "",
            "style": "IPY_MODEL_0538516fdd7044d68d689fa285057509",
            "value": "16/16[01:19&lt;00:00,3.91s/it]"
          }
        },
        "65a23814a7ee4ab9ac068f3c51f38d3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "737369715f2d41c5bbdf54d2f4538819": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4a366d7e22c449cada4ccd9641302d9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c183125c03f7472f8ce34aa98c6d6dd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e006307864cb432eb8efdbd80e20a3cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1dc855d3f9284307a66b15ef704e677a",
            "placeholder": "",
            "style": "IPY_MODEL_c183125c03f7472f8ce34aa98c6d6dd4",
            "value": "Loadingcheckpointshards:100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}