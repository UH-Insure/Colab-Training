{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tam1444AH/UH-Insure-NSA/blob/main/notebooks/codeLLMFT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhsfjOTsdjHg",
        "outputId": "2ed6a546-53f2-44a7-a70f-05eca35d0451",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nbstripout in /usr/local/lib/python3.12/dist-packages (0.8.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.12/dist-packages (from nbstripout) (5.10.4)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat->nbstripout) (2.21.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat->nbstripout) (4.25.1)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.12/dist-packages (from nbformat->nbstripout) (5.9.1)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.12/dist-packages (from nbformat->nbstripout) (5.7.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->nbstripout) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->nbstripout) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->nbstripout) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->nbstripout) (0.27.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->nbstripout) (4.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from referencing>=0.28.4->jsonschema>=2.6->nbformat->nbstripout) (4.15.0)\n",
            "Repo 'Colab-Training' exists, pulling latest changes...\n",
            "HEAD is now at b7d9bd5 Missing import\n",
            "Already up to date.\n",
            "* \u001b[32mmain\u001b[m\n",
            "  \u001b[31mremotes/origin/HEAD\u001b[m -> origin/main\n",
            "  \u001b[31mremotes/origin/codex/incorporate-wandb-and-refactor-training-loop\u001b[m\n",
            "  \u001b[31mremotes/origin/main\u001b[m\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"false\"  # or \"true\" to mute\n",
        "import wandb\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "%pip install nbstripout\n",
        "\n",
        "REPO_URL=\"https://github.com/UH-Insure/Colab-Training.git\"\n",
        "REPO=\"Colab-Training\"\n",
        "\n",
        "os.chdir(\"/content\")\n",
        "\n",
        "# If repo exists, update it; otherwise, clone fresh\n",
        "if os.path.exists(REPO):\n",
        "    print(f\"Repo '{REPO}' exists, pulling latest changes...\")\n",
        "    os.chdir(REPO)\n",
        "    !git reset --hard HEAD   # optional: discard local changes\n",
        "    !git pull\n",
        "else:\n",
        "    print(f\"Cloning repo '{REPO}'...\")\n",
        "    !git clone \"$REPO_URL\" \"$REPO\"\n",
        "    os.chdir(REPO)\n",
        "\n",
        "!nbstripout --install\n",
        "!git branch -a\n",
        "\n",
        "\n",
        "# Install dependencies if present\n",
        "if os.path.exists(\"requirements.txt\"):\n",
        "    !pip install -r requirements.txt\n",
        "if os.path.exists(\"pyproject.toml\"):\n",
        "    !pip install -e .\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d83XoDttGhvR",
        "outputId": "7abc8e7f-c99e-4c37-fa71-53720296aa61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World!\n"
          ]
        }
      ],
      "source": [
        "from model.test import test\n",
        "test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYAEaTXfi5IL",
        "outputId": "48f2fea4-8299-48ed-fce8-d907ae868755"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjoshuareedenterprises\u001b[0m (\u001b[33mjoshuareedenterprises-university-of-houston\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logged in as: j05hr3d\n"
          ]
        }
      ],
      "source": [
        "!pip -q install -U huggingface_hub hf_transfer\n",
        "!export HF_HUB_ENABLE_HF_TRANSFER=1\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from huggingface_hub import login, whoami\n",
        "\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"  # mitigate fragmentation\n",
        "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"\n",
        "HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "WANDB_TOKEN = userdata.get('WANDB_KEY')\n",
        "wandb.login(key=WANDB_TOKEN, relogin=True)\n",
        "login(token=HF_TOKEN, add_to_git_credential=True)  # also sets Git creds for LFS\n",
        "\n",
        "print(\"Logged in as:\", whoami(token=HF_TOKEN)[\"name\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "id": "dlU0gNQY_guS"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "U2UgisCib_pa"
      },
      "outputs": [],
      "source": [
        "#os.chdir(\"/content\")\n",
        "!pip install -q transformers datasets\n",
        "\n",
        "import json, random\n",
        "from datasets import load_dataset, Dataset, concatenate_datasets\n",
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_exHfg8sVH3J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "d43bd7dd-cb5c-4aa5-d243-c8301d745a29"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.22.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/Colab-Training/wandb/run-20251025_195931-qar45vgj</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/joshuareedenterprises-university-of-houston/qwen3coder-finetune-fp16/runs/qar45vgj' target=\"_blank\">run-20251025-195931</a></strong> to <a href='https://wandb.ai/joshuareedenterprises-university-of-houston/qwen3coder-finetune-fp16' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/joshuareedenterprises-university-of-houston/qwen3coder-finetune-fp16' target=\"_blank\">https://wandb.ai/joshuareedenterprises-university-of-houston/qwen3coder-finetune-fp16</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/joshuareedenterprises-university-of-houston/qwen3coder-finetune-fp16/runs/qar45vgj' target=\"_blank\">https://wandb.ai/joshuareedenterprises-university-of-houston/qwen3coder-finetune-fp16/runs/qar45vgj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/joshuareedenterprises-university-of-houston/qwen3coder-finetune-fp16/runs/qar45vgj?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7bb2c268f050>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "!pip install -q transformers datasets peft flash-attn\n",
        "\n",
        "MODEL = \"Qwen/Qwen3-Coder-30B-A3B-Instruct\"\n",
        "DATASET = \"/content/Colab-Training/MOC/all_hybrid.jsonl\"\n",
        "DATA_COLUMN = \"content\"\n",
        "\n",
        "SEQ_LENGTH = 4096\n",
        "\n",
        "# Training arguments\n",
        "MAX_STEPS = 200\n",
        "NUM_EPOCHS = 1\n",
        "BATCH_SIZE = 12\n",
        "GR_ACC_STEPS = 2\n",
        "LR = 2e-4                     # learning_rate\n",
        "WARMUP_RATIO = 0.03\n",
        "WEIGHT_DECAY = 0.01\n",
        "LR_SCHEDULER_TYPE = \"cosine\"  # lr_scheduler_type\n",
        "WEIGHT_DECAY = 0.05  # weight_decay\n",
        "NUM_WARMUP_STEPS = 100  # num_warmup_steps\n",
        "EVAL_FREQ = 25\n",
        "SAVE_FREQ = 50\n",
        "LOG_FREQ = 10\n",
        "OUTPUT_DIR = \"peft-FT-3-Coder-30b-v2\"  # output_dir\n",
        "BF16 = True  # bf16\n",
        "FP16 = False  # no_fp16\n",
        "\n",
        "# FIM trasformations arguments\n",
        "FIM_RATE = 0.25  # fim_rate\n",
        "FIM_SPM_RATE = 0.5  # fim_spm_rate\n",
        "\n",
        "\n",
        "# LORA\n",
        "LORA_R = 128  # lora_r\n",
        "LORA_ALPHA = LORA_R * 2  # lora_alpha\n",
        "LORA_DROPOUT = 0.05  # lora_dropout\n",
        "LORA_TARGET_MODULES = [\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\"gate_proj\",\"up_proj\",\"down_proj\"]\n",
        "#LORA_TARGET_MODULES = [\"q_proj\",\"k_proj\",\"v_proj\"]  # lora_target_modules\n",
        "\n",
        "# bitsandbytes config\n",
        "USE_NESTED_QUANT = True  # use_nested_quant\n",
        "BNB_4BIT_COMPUTE_DTYPE = \"bfloat16\"  # bnb_4bit_compute_dtype\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "\n",
        "wandb.init(\n",
        "    project=\"qwen3coder-finetune-fp16\",\n",
        "    name=f\"run-{datetime.now().strftime('%Y%m%d-%H%M%S')}\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8lRTsgnlVcMN"
      },
      "outputs": [],
      "source": [
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    logging,\n",
        "    set_seed,\n",
        "    BitsAndBytesConfig,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    TrainerCallback\n",
        ")\n",
        "\n",
        "set_seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlcO8zw22Ycd",
        "outputId": "f52f611c-005d-40c8-aa2a-26c147a72193"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['filename', 'filetype', 'content', 'variant', 'set'])\n",
            "dict_keys(['filename', 'filetype', 'content', 'variant', 'set'])\n",
            "9 1\n",
            "The character to token ratio of the dataset is: 3.11\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "from model.dataset.util import chars_token_ratio, split_by_filetype\n",
        "\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.set_float32_matmul_precision(\"high\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    MODEL,\n",
        "    padding_side=\"right\",\n",
        "    add_eos_token=True,\n",
        "    add_bos_token=True,\n",
        "    trust_remote_code=True,\n",
        "    use_fast=False,\n",
        ")\n",
        "\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "train_ds, eval_ds = split_by_filetype(\n",
        "    dataset_path=DATASET,\n",
        "    seed=SEED,\n",
        "    test_size=0.1,\n",
        "    filetypes=[\"cry\", \"saw\", \"txt\"]\n",
        ")\n",
        "print(train_ds[0].keys())\n",
        "assert DATA_COLUMN in train_ds.column_names, f\"Missing '{DATA_COLUMN}' in JSONL!\"\n",
        "print(eval_ds[0].keys())\n",
        "assert DATA_COLUMN in eval_ds.column_names, f\"Missing '{DATA_COLUMN}' in JSONL!\"\n",
        "print(len(train_ds), len(eval_ds))\n",
        "chars_per_token = chars_token_ratio(train_ds, tokenizer, DATA_COLUMN)\n",
        "print(f\"The character to token ratio of the dataset is: {chars_per_token:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_WIZWSfIJBaS"
      },
      "outputs": [],
      "source": [
        "from model.dataset.util import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "tC8QbrmIJBcm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b3c164f-d32e-4d9b-f150-2ea47e07f04c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Empirical dataset length = 2 sequences (~6290 tokens)\n",
            "[INFO] Empirical dataset length = 1 sequences (~555 tokens)\n"
          ]
        }
      ],
      "source": [
        "from model.dataset.constantLengthDataset import ConstantLengthDataset\n",
        "import torch\n",
        "\n",
        "\n",
        "train_dataset = ConstantLengthDataset(\n",
        "        tokenizer=tokenizer,\n",
        "        dataset=train_ds,\n",
        "        infinite=False,\n",
        "        seq_length=SEQ_LENGTH,\n",
        "        chars_per_token=chars_per_token,\n",
        "        content_field=DATA_COLUMN,\n",
        "        fim_rate=FIM_RATE,\n",
        "        fim_spm_rate=FIM_SPM_RATE,\n",
        "        overlap_ratio=0.125,\n",
        "        seed=SEED,\n",
        "        already_tokenized=False,\n",
        ")\n",
        "eval_dataset = ConstantLengthDataset(\n",
        "        tokenizer=tokenizer,\n",
        "        dataset=eval_ds,\n",
        "        infinite=False,\n",
        "        seq_length=SEQ_LENGTH,\n",
        "        chars_per_token=chars_per_token,\n",
        "        content_field=DATA_COLUMN,\n",
        "        fim_rate=FIM_RATE,\n",
        "        fim_spm_rate=FIM_SPM_RATE,\n",
        "        overlap_ratio=0.125,\n",
        "        seed=SEED,\n",
        "        already_tokenized=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "KltZZq0QbJFP"
      },
      "outputs": [],
      "source": [
        "import os, gc, torch\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "gc.collect(); torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601,
          "referenced_widgets": [
            "1a8e469232d04d309262a8aa0d5c915d",
            "02b33eba7a2d46e08cefd2bd71592bb6",
            "43f420c79ac14e819ff3398e457e3203",
            "9816707415914be0a2d30956a5bd566d",
            "6c1f80e098c7497c88698a8d8ea2e716",
            "80811fe0243a45b89ed273b8bc7c0355",
            "4a00069f7ba44dbe9595c02bba12d4bf",
            "6098a5b77807434bbb37b8361e9a8947",
            "3e5a4dcb3634479fb1167d4438798671",
            "1ba68a77d5aa4ae4a63b450c36580ef0",
            "c700999b777e4b76a7dff162e9dc0b6c"
          ]
        },
        "id": "6r7iIuyAJBg0",
        "outputId": "1c197772-3521-4e3a-bb2b-03d4b542287e",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.48.1)\n",
            "Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.8.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\n",
            "{'<|fim_prefix|>': 151659, '<|fim_middle|>': 151660, '<|fim_suffix|>': 151661, '<|fim_pad|>': 151662}\n",
            "additional_special_tokens: ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/16 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1a8e469232d04d309262a8aa0d5c915d"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "! pip install -U bitsandbytes\n",
        "\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "from peft.tuners.lora import LoraLayer\n",
        "\n",
        "names = [\"<|fim_prefix|>\", \"<|fim_middle|>\", \"<|fim_suffix|>\", \"<|fim_pad|>\"]\n",
        "ids = [tokenizer.convert_tokens_to_ids(t) for t in names]\n",
        "print(dict(zip(names, ids)))\n",
        "print(\"additional_special_tokens:\", tokenizer.special_tokens_map.get(\"additional_special_tokens\"))\n",
        "\n",
        "\n",
        "# 4-bit quantization\n",
        "compute_dtype = getattr(torch, BNB_4BIT_COMPUTE_DTYPE)\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=compute_dtype,\n",
        "    bnb_4bit_use_double_quant=USE_NESTED_QUANT,\n",
        ")\n",
        "\n",
        "base = AutoModelForCausalLM.from_pretrained(\n",
        "        MODEL,\n",
        "        load_in_8bit=False,\n",
        "        quantization_config=bnb_config,\n",
        "        torch_dtype=torch.float16,\n",
        "        device_map=\"auto\",\n",
        "        use_cache=False,\n",
        "        trust_remote_code=True,\n",
        "        attn_implementation=\"flash_attention_2\",\n",
        ")\n",
        "\n",
        "base = prepare_model_for_kbit_training(base)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5monDpDR8_n",
        "outputId": "6b41c531-ffaf-44da-9310-c858732095aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ATTN: Qwen3MoeAttention(\n",
            "  (q_proj): Linear4bit(in_features=2048, out_features=4096, bias=False)\n",
            "  (k_proj): Linear4bit(in_features=2048, out_features=512, bias=False)\n",
            "  (v_proj): Linear4bit(in_features=2048, out_features=512, bias=False)\n",
            "  (o_proj): Linear4bit(in_features=4096, out_features=2048, bias=False)\n",
            "  (q_norm): Qwen3MoeRMSNorm((128,), eps=1e-06)\n",
            "  (k_norm): Qwen3MoeRMSNorm((128,), eps=1e-06)\n",
            ")\n",
            "MLP: Qwen3MoeSparseMoeBlock(\n",
            "  (gate): Linear4bit(in_features=2048, out_features=128, bias=False)\n",
            "  (experts): ModuleList(\n",
            "    (0-127): 128 x Qwen3MoeMLP(\n",
            "      (gate_proj): Linear4bit(in_features=2048, out_features=768, bias=False)\n",
            "      (up_proj): Linear4bit(in_features=2048, out_features=768, bias=False)\n",
            "      (down_proj): Linear4bit(in_features=768, out_features=2048, bias=False)\n",
            "      (act_fn): SiLUActivation()\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "blk = base.model.layers[0]           # Llama/Qwen-style\n",
        "print(\"ATTN:\", blk.self_attn)         # has q_proj, k_proj, v_proj, o_proj\n",
        "print(\"MLP:\", blk.mlp)\n",
        "target_modules = LORA_TARGET_MODULES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RFqsImVJBjW",
        "outputId": "95758586-7739-421c-c231-939b1cf0ab5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 843,841,536 || all params: 31,375,964,160 || trainable%: 2.6895\n"
          ]
        }
      ],
      "source": [
        "# Set up lora\n",
        "from peft import PeftModel\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha=LORA_ALPHA,\n",
        "    lora_dropout=LORA_DROPOUT,\n",
        "    r=LORA_R,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules=target_modules,\n",
        ")\n",
        "\n",
        "# model = PeftModel.from_pretrained(base, \"tam2003/peft-FT-3-Coder-30b\") # If your just trying to test the model.\n",
        "model = get_peft_model(base, peft_config) # If you want to continue training.\n",
        "\n",
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "2bApn9UHJz7F"
      },
      "outputs": [],
      "source": [
        "collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "If0nsW1tJNQJ",
        "outputId": "71e30d67-dbb1-4636-e216-e3db2cf30e1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 9\n",
            "Sample text:\n",
            "\n",
            "x = [True, False]\n",
            "y = [False, True]\n",
            "z = x + y\n",
            "\n",
            "property p1 = z == 3\n",
            "\n",
            "xx = [[True,False]]\n",
            "yy = [[False, True]]\n",
            "zz = xx + yy\n",
            "\n",
            "\n",
            "\n",
            "t : {a} [a*3] -> [a*3][a*3]\n",
            "t d = zero\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_ds.start_iteration = 0\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    num_train_epochs=NUM_EPOCHS,\n",
        "    per_device_train_batch_size=6,\n",
        "    per_device_eval_batch_size=6,\n",
        "    gradient_accumulation_steps=GR_ACC_STEPS,\n",
        "    gradient_checkpointing=False,\n",
        "    learning_rate=LR,\n",
        "    lr_scheduler_type=LR_SCHEDULER_TYPE,\n",
        "    warmup_steps=4,\n",
        "    #warmup_ratio=WARMUP_RATIO,\n",
        "    weight_decay=WEIGHT_DECAY,\n",
        "    fp16=True,\n",
        "    bf16=False,\n",
        "    optim=\"paged_adamw_8bit\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    report_to=\"wandb\",\n",
        "    push_to_hub=True,\n",
        "    dataloader_drop_last=False,\n",
        "    dataloader_num_workers=2,\n",
        "    include_tokens_per_second=True,\n",
        "    max_grad_norm=0.3,\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    greater_is_better=False,\n",
        "    dataloader_pin_memory=True,\n",
        "    save_safetensors=True,\n",
        "    seed=SEED,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hrZA8wr0JNSd",
        "outputId": "b30bef5c-a16a-4c92-cc3e-43aa391d02ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1000699993.py:5: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.22.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/Colab-Training/wandb/run-20251025_201049-jcb63l9w</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/joshuareedenterprises-university-of-houston/huggingface/runs/jcb63l9w' target=\"_blank\">ethereal-pyramid-1</a></strong> to <a href='https://wandb.ai/joshuareedenterprises-university-of-houston/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/joshuareedenterprises-university-of-houston/huggingface' target=\"_blank\">https://wandb.ai/joshuareedenterprises-university-of-houston/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/joshuareedenterprises-university-of-houston/huggingface/runs/jcb63l9w' target=\"_blank\">https://wandb.ai/joshuareedenterprises-university-of-houston/huggingface/runs/jcb63l9w</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1/1 01:19, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.017500</td>\n",
              "      <td>0.905666</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:751: UserWarning: Length of IterableDataset <model.dataset.constantLengthDataset.ConstantLengthDataset object at 0x7bb1ecd8f830> was reported to be 1(when accessing len(dataloader)), but 2 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> Epoch 1 | eval_loss=0.9057 | perplexity=2.474\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed in 215.07 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:751: UserWarning: Length of IterableDataset <model.dataset.constantLengthDataset.ConstantLengthDataset object at 0x7bb1ecd8f830> was reported to be 1(when accessing len(dataloader)), but 2 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1/1 00:13]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> Epoch 1 | eval_loss=0.9057 | perplexity=2.474\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁▁</td></tr><tr><td>eval/runtime</td><td>▁█</td></tr><tr><td>eval/samples_per_second</td><td>▁▁</td></tr><tr><td>eval/steps_per_second</td><td>▁▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁▁</td></tr><tr><td>train/grad_norm</td><td>▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/train_tokens_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.90567</td></tr><tr><td>eval/runtime</td><td>30.4273</td></tr><tr><td>eval/samples_per_second</td><td>0.033</td></tr><tr><td>eval/steps_per_second</td><td>0.033</td></tr><tr><td>total_flos</td><td>1526897011851264.0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>1</td></tr><tr><td>train/grad_norm</td><td>0.47211</td></tr><tr><td>train/learning_rate</td><td>0</td></tr><tr><td>train/loss</td><td>1.0175</td></tr><tr><td>+5</td><td>...</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">ethereal-pyramid-1</strong> at: <a href='https://wandb.ai/joshuareedenterprises-university-of-houston/huggingface/runs/jcb63l9w' target=\"_blank\">https://wandb.ai/joshuareedenterprises-university-of-houston/huggingface/runs/jcb63l9w</a><br> View project at: <a href='https://wandb.ai/joshuareedenterprises-university-of-houston/huggingface' target=\"_blank\">https://wandb.ai/joshuareedenterprises-university-of-houston/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251025_201049-jcb63l9w/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval loss = 0.91, Perplexity = 2.47\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "from model.dataset.util import PerplexityCallback, EpochToDatasetCallback\n",
        "from time import time\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=collator,\n",
        "    callbacks=[PerplexityCallback(), EpochToDatasetCallback(train_dataset)],\n",
        ")\n",
        "train_start_time = time()\n",
        "print(\"Training...\")\n",
        "trainer.train(resume_from_checkpoint=False)\n",
        "train_end_time = time()\n",
        "print(f\"Training completed in {train_end_time - train_start_time:.2f} seconds.\")\n",
        "eval_results = trainer.evaluate()\n",
        "wandb.finish()\n",
        "eval_loss = eval_results[\"eval_loss\"]\n",
        "perplexity = math.exp(eval_loss)\n",
        "print(f\"Eval loss = {eval_loss:.2f}, Perplexity = {perplexity:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-jKxX1UJdu5"
      },
      "outputs": [],
      "source": [
        "trainer.push_to_hub()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1a8e469232d04d309262a8aa0d5c915d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02b33eba7a2d46e08cefd2bd71592bb6",
              "IPY_MODEL_43f420c79ac14e819ff3398e457e3203",
              "IPY_MODEL_9816707415914be0a2d30956a5bd566d"
            ],
            "layout": "IPY_MODEL_6c1f80e098c7497c88698a8d8ea2e716"
          }
        },
        "02b33eba7a2d46e08cefd2bd71592bb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80811fe0243a45b89ed273b8bc7c0355",
            "placeholder": "​",
            "style": "IPY_MODEL_4a00069f7ba44dbe9595c02bba12d4bf",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "43f420c79ac14e819ff3398e457e3203": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6098a5b77807434bbb37b8361e9a8947",
            "max": 16,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3e5a4dcb3634479fb1167d4438798671",
            "value": 16
          }
        },
        "9816707415914be0a2d30956a5bd566d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ba68a77d5aa4ae4a63b450c36580ef0",
            "placeholder": "​",
            "style": "IPY_MODEL_c700999b777e4b76a7dff162e9dc0b6c",
            "value": " 16/16 [01:24&lt;00:00,  4.19s/it]"
          }
        },
        "6c1f80e098c7497c88698a8d8ea2e716": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80811fe0243a45b89ed273b8bc7c0355": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a00069f7ba44dbe9595c02bba12d4bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6098a5b77807434bbb37b8361e9a8947": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e5a4dcb3634479fb1167d4438798671": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1ba68a77d5aa4ae4a63b450c36580ef0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c700999b777e4b76a7dff162e9dc0b6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}